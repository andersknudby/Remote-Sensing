{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "GEE Lab 3.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/andersknudby/Remote-Sensing/blob/master/GEE%20Lab%203.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZrD5e3ItlOSl"
      },
      "source": [
        "#Lab 3: MODIS Time Series and Graphing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RSD6EQTqpNfo"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "In this lab we will continue working with the Google Earth Engine python API in Google Colab. We will explore the available MODIS datasets and create a sea-surface temperature (SST) time series with MODIS. We will also explore some python graphing libraries to create interactive plots of earth engine data.\n",
        "\n",
        "\n",
        "**Files you need:** N/A\n",
        "\n",
        "**Preparation:**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1Ydjvj8pR4q"
      },
      "source": [
        "## Steps"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i-birGdTlidg"
      },
      "source": [
        "###| 1. Imports, installation, authentication, initialization\n",
        "\n",
        "Our first step is to get the notebook set up. Review the description in the first lab if you want a refresher on why we need to do this!\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JqloY9sL4SdQ"
      },
      "source": [
        "# Install geemap library so that we can use it to view images on an interactive map\n",
        "## You may get a runtime warning - you can ignore that\n",
        "!pip install geemap"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BrNt-2X2eSxW"
      },
      "source": [
        "# Import the necessary libraries\n",
        "import ee\n",
        "import numpy as np\n",
        "import geemap as geemap\n",
        "import pprint\n",
        "\n",
        "import pandas as pd\n",
        "import altair as alt\n",
        "import folium\n",
        "\n",
        "# Set up a 'pretty printer' to print ...\n",
        "pp = pprint.PrettyPrinter(depth=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCgdEO86zQX5"
      },
      "source": [
        "# Authenticate and initialize this instance of GEE in Google Colab\n",
        "## Follow the prompts and fill in authentication code\n",
        "ee.Authenticate()\n",
        "ee.Initialize()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W-mfqz8w53CR"
      },
      "source": [
        "### | 2. MODIS\n",
        "\n",
        "So far in these GEE labs, we have almost exclusively used Landsat data. Landsat data is good for learning GEE because it has well-known TOA and surface reflectance products that cover a very long time period, has a good spectral resolution,  and has decent spatial resolution for many applications. Because of this, there is also a lot of supporting documentation both by Google and by other users of GEE for using Landsat imagery in GEE. \n",
        "\n",
        "However, one of the main benefits of using GEE is how easy it is to access huge amounts of *different kinds of data*. GEE combines whole collections of imagery and imagery products from a variety of satellites and organizations  and makes it easy to analyze them, without having to download individual images from the source.\n",
        "\n",
        "So, to better understand the power of Google Earth Engine, and to expose you to some more code you may be able to use in the future, for this lab we will take a look at moderate spatial resolution, high temporal resolution data with MODIS.\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJdJvI3FouTs"
      },
      "source": [
        "#### MODIS Info\n",
        "\n",
        "MODIS (or Moderate Resolution Imaging Spectroradiometer) is an instrument aboard two complimentary satellites launched by NASA: **Terra** and **Aqua**. Combined, the Terra and Aqua MODIS instruments image the entire surface of the Earth every 1 to 2 days, acquiring data in 36 spectral bands at 250 m (bands 1–2), 500 m (bands 3–7), and 1000 m (bands 8–36) resolution. \n",
        " \n",
        "With its low-ish spatial resolution but high temporal resolution, MODIS data are useful to track changes in the landscape over time.\n",
        "\n",
        "Like Landsat, MODIS has data products in addition to the 36 band imagery that you can access from the GEE catalogue. Check out all the available data in the [MODIS section of the GEE catalogue](https://developers.google.com/earth-engine/datasets/catalog/modis).\n",
        "\n",
        "The structure of MODIS data is a bit more complicated than what we have dealt with so far. The data from MODIS is processed by a variety of groups (depending on the product) in order to create the available data products. Unlike some other satellite data, MODIS does not provide unprocessed scenes to the general public. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SORQDynznaf2"
      },
      "source": [
        "#### Using MODIS Surface Reflectance\n",
        "To start, we will use the MOD09GA.006 Terra Surface Reflectance Daily Global 1km and 500m daily data product. This collection has surface reflectance available at 500m resolution, as well as pixel quality assurance (QA) bit information at the 1000m resolution. These QA bits contain information about cloud contamination, as well as the number of observations that make up a given pixel -- remember, these pixels are data ***products*** and so can represent >1 observation.\n",
        "\n",
        "Masking unwanted pixels is done in a similar way as for Landsat, using the MODIS pixel QA bands. In this case we will create functions to mask both cloud pixels (from the `state_1km` QA band) and pixels with no observations (from the `num_observation_1km` band). \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L4-syH_VgLSV"
      },
      "source": [
        "#Calculate how frequently a location is labeled as clear (i.e. non-cloudy)\n",
        "#according to the \"internal cloud algorithm flag\" of the MODIS \"state 1km\"\n",
        "#QA band.\n",
        "\n",
        "# A function to mask out pixels that did not have observations.\n",
        "def maskEmptyPixels(image):\n",
        "  # Find pixels with >0 observations and mask out all other pixels \n",
        "  withObs = image.select('num_observations_1km').gt(0)\n",
        "  return image.updateMask(withObs)\n",
        "\n",
        "# A function to mask out cloudy pixels.\n",
        "def maskClouds(image):\n",
        "  #Select the QA band.\n",
        "  QA = image.select('state_1km')\n",
        "  # Make a mask to get bit 10, the internal_cloud_algorithm_flag bit.\n",
        "  bitMask = 1 << 10\n",
        "  # Return an image masking out cloudy areas.\n",
        "  return image.updateMask(QA.bitwiseAnd(bitMask).eq(0))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8pkxC_wnB3s"
      },
      "source": [
        "Now let's apply the masking functions to a collection and display it on the map"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P2ecKhTHnAlF"
      },
      "source": [
        "# Start with an image collection for summer 2010 and apply masks\n",
        "summer2010 = ee.ImageCollection('MODIS/006/MOD09GA')\\\n",
        "        .filterDate('2010-04-01', '2010-09-30')\\\n",
        "        .map(maskEmptyPixels)\\\n",
        "        .map(maskClouds)\n",
        "\n",
        "# note that slashes \\ are used in the code above to allow another line of code for \n",
        "# formatting appearance (the code could all be on one long line, if you wanted)\n",
        "# in some cases, code automatically continues to the next line, e.g. when there are commas,\n",
        "# but sometimes we need to tell the code that we are continuing on the next line with a \\\n",
        "\n",
        "# Get the median pixel value for summer 2010\n",
        "# Recall from the last lab that this is a temporal reducer\n",
        "summer2010med = summer2010.median()\n",
        "\n",
        "# Note that true colour for this MODIS dataset is Band 1 in Red, Band 4 in Green, and Band 3 in Blue\n",
        "visParams = {'bands': ['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03'],\n",
        "     'gain': 0.07,\n",
        "     'gamma': 1.4\n",
        "    }\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(summer2010med,visParams,'Summer 2010 Median SR')\n",
        "Map.addLayerControl()\n",
        "Map.setCenter(41.92,32.36,5)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2hHijI4Lo4Rb"
      },
      "source": [
        "Notice that we did not filter the bounds of the image so we have created a median for the entire globe (where there is data for summer 2010). So you can pan and zoom to any area you like and see what the data look like there.\n",
        "\n",
        "Because of the high temporal frequency of MODIS, the resulting imagery is pretty great, because the median pixel is potentially calculated from as many as 182 pixels. That is, one pixel per day for every day from April 1st to September 30th (182 days).\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVAOx0gNtM-2"
      },
      "source": [
        "#### Using other MODIS data products\n",
        "\n",
        "In addition to the surface reflectance products, MODIS also provides special data products calculated from the data. For the next example, we will use the Ocean Color Standard Mapped Image MODIS Aqua Data. \n",
        "\n",
        "This dataset is a level 3 product that includes ocean color and satellite ocean biology data produced by NASA's Earth Science Data Systems (ESDS) program. It includes bands that are useful for calculating ocean biology data because of their narrow wavelengths, as well as some bands of pre-calculated data such as chlorophyll-a concentration and sea-surface temperature (SST).\n",
        "\n",
        "Let's check out the SST band and use it to look at El Nino and La Nina years. If you need a quick refresher, check out the NASA kid science pages for [El Nino](https://spaceplace.nasa.gov/el-nino/en/) and [La Nina](https://spaceplace.nasa.gov/la-nina/en/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qmdAu8pMA-tN"
      },
      "source": [
        "# Load MODIS Ocean Colour Image Collection\n",
        "modisOceanColor = ee.ImageCollection('NASA/OCEANDATA/MODIS-Aqua/L3SMI');\n",
        "\n",
        "# Create a collection from the SST (sea surface temperature) band\n",
        "sst = modisOceanColor.select(['sst'])\n",
        "\n",
        "# Calculate median SST values for winter 2015/2016 - an El Nino year\n",
        "sstElNino = sst.filterDate('2015-12-01', '2016-02-28').median()\n",
        "\n",
        "# Calculate median SST values for winter 2010/2011 - a La Nina year\n",
        "sstLaNina = sst.filterDate('2010-12-01', '2011-02-28').median()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oY80LeCwc18S"
      },
      "source": [
        "# Create vis parameters for SST with a palette that goes from blue to red\n",
        "vis = {'min': -4, 'max': 35, 'palette': '#2166AC,#4393C3,#92C5DE,#D1E5F0,#B2182B'};\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(sstElNino,vis,'El Nino')\n",
        "Map.addLayer(sstLaNina,vis,'La Nina')\n",
        "# set the map centre as the middle of the Pacific at a zoom level of two (pretty zoomed out)\n",
        "Map.setCenter(-146.25,0,2)\n",
        "Map.addLayerControl()\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzcOPYxRxJsz"
      },
      "source": [
        "Toggle the layers on and off to compare the sea surface temperature for El Nino and La Nina years. \n",
        "\n",
        "Recall from your climatology courses (or the NASA Kids pages linked above) that El Nino results from weaker trade winds moving from East to West resulting in warmer waters toward the west coast of Central/South America. La Nina occurs in years with stronger than normal trade winds, resulting in cooler waters off the west coast of Central/South America.\n",
        "\n",
        "The effect of the El Niño-Southern Oscillation (ENSO) is best visualized as a temperature anomaly in order to show the effect on areas that still have relatively cool waters, rather than an absolute temperature which shows 10-degree water as light blue, regardless of whether 10 degrees is colder or warmer than normal conditions. However, these two layers still do a decent job of showing how MODIS can be used to look at large scale data patterns. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sjpjtw85uzZ1"
      },
      "source": [
        "### | 3. Time Series Charts with MODIS\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B9yQRxD_LuQv"
      },
      "source": [
        "Time series analysis involves looking at data over time to detect and describe change. With imagery this can be done in the form of a video, or, more simply, by extracting some data from the imagery and displaying the change through time on a graph.\n",
        "\n",
        "The Google Earth Engine Code Editor has a built in charting library called Chart.UI that integrates some earth engine functionality like reducers into chart functions to create easy data visualizations.\n",
        "\n",
        "Unfortunately, Chart.UI does not work in the python API, so we need to create some reducing functions that we can apply to the image collections before plotting with some normal python charting libraries. We will look at two charting libraries in this lab: the simple **matplotlib**, and **Altair**, which is a library that is useful for creating nice interactive maps."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TcERJY8SMu0L"
      },
      "source": [
        "#### Create Reducing Function\n",
        "\n",
        "In order to create a time series analysis, we can either look at the change in pixel values over time for a **single pixel** (at a defined point), or we can look at the change in values over time for a **region of pixels** (within a defined geometry). In both cases, we need to use a reducer to summarize the values for an area before plotting the time series. \n",
        "\n",
        "As mentioned, the Chart.UI library incorporates this reducing capability into its chart functions, but in the Python API in colab, we need to define the functions that will apply a reducer across an image collection before we plot the time series. The functions below were taken directly from a [GEE Python Charting Tutorial ](https://colab.research.google.com/github/google/earthengine-community/blob/master/tutorials/time-series-visualization-with-altair/index.ipynb). \n",
        "\n",
        "The first function is actually used to create a function in a nifty bit of python. The code below defines a reusable function that can perform the reducing task for different datasets. The function accepts arguments such as scale and reduction method to parameterize the operation for each particular analysis.\n",
        "\n",
        "Do not worry too much about trying to understand *how* the functions work. For our purposes, we just need to know that they work (they do) and that we can re-use them to convert image collections to tables.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBTQQxq02bgM"
      },
      "source": [
        "# Define a function (and embedded function) for reducing a region for charting\n",
        "# See the function descriptions defined in red within the functions\n",
        "\n",
        "def create_reduce_region_function(geometry,\n",
        "                                  reducer=ee.Reducer.median(),\n",
        "                                  scale=500,\n",
        "                                  crs='EPSG:4326',\n",
        "                                  bestEffort=True,\n",
        "                                  maxPixels=1e13,\n",
        "                                  tileScale=4):\n",
        "  \"\"\"Creates a region reduction function.\n",
        "\n",
        "  Creates a region reduction function intended to be used as the input function\n",
        "  to ee.ImageCollection.map() for reducing pixels intersecting a provided region\n",
        "  to a statistic for each image in a collection. See ee.Image.reduceRegion()\n",
        "  documentation for more details.\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def reduce_region_function(img):\n",
        "    \"\"\"\n",
        "      Function returns\n",
        "      An ee.Feature that contains properties representing the image region\n",
        "      reduction results per band and the image timestamp formatted as\n",
        "      milliseconds from Unix epoch (included to enable time series plotting).\n",
        "    \"\"\"\n",
        "\n",
        "    stat = img.reduceRegion(\n",
        "        reducer=reducer,\n",
        "        geometry=geometry,\n",
        "        scale=scale,\n",
        "        crs=crs,\n",
        "        bestEffort=bestEffort,\n",
        "        maxPixels=maxPixels,\n",
        "        tileScale=tileScale)\n",
        "\n",
        "    return ee.Feature(geometry, stat).set({'millis': img.date().millis()})\n",
        "  return reduce_region_function\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzSKWE2jaAOx"
      },
      "source": [
        "Now that we have defined our functions, we can use them on an image collection and a region in order to get a table we can use as input to some charting library functions."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LgG_ky46bCCB"
      },
      "source": [
        "# Load MODIS Ocean Colour Image Collection\n",
        "modisOceanColor = ee.ImageCollection('NASA/OCEANDATA/MODIS-Aqua/L3SMI');\n",
        "\n",
        "# Create a collection from the SST (sea surface temperature) band\n",
        "sst = modisOceanColor.select(['sst'])\n",
        "\n",
        "# Define an area of interest (aoi)\n",
        "# We will look at Lake Erie \n",
        "aoi = ee.Geometry.Polygon([[-83.594,41.326],\n",
        "                           [-78.782,41.326],\n",
        "                           [-78.782,42.972],\n",
        "                           [-83.594,42.972],\n",
        "                           [-83.594,41.326]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCUVO81Oogvb"
      },
      "source": [
        "# Check out the AOI if you want\n",
        "# If you know where Lake Erie is, feel free to skip this cell\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(aoi,{},'AOI')\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3jLOFWjeVGj"
      },
      "source": [
        "The next code chunk does three things:\n",
        "1. Assigns the reduce function with specific parameters to the function, `reduce_sst`. This will make it simpler to map the function across the image collection.\n",
        "2. Maps the function over the `sst` image collection to reduce each image.\n",
        "3. Filters out any resulting features that have null computed values (occurs when all pixels in an AOI are masked)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kJsi6sRNbUqL"
      },
      "source": [
        "# Use the above defined function to create a reducing function specific to the SST dataset\n",
        "## We are going to leave most of the arguments as their defaults (see the above code)\n",
        "## except geometry which we set to our aoi, the reducer which we will set as the median\n",
        "reduce_sst = create_reduce_region_function(\n",
        "    geometry=aoi, reducer=ee.Reducer.median())\n",
        "\n",
        "# Convert the image collection to a feature collection with the reducer function\n",
        "## this step just applies the function we created above (reduce_sst), with its defined inputs to our\n",
        "## image collection\n",
        "sst_stat_fc = ee.FeatureCollection(sst.map(reduce_sst))\n",
        "\n",
        "# Filter out null values based on bandnames of the first image in the feature collection\n",
        "sst_stat_fc = sst_stat_fc.filter(\n",
        "    ee.Filter.notNull(sst.first().bandNames()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DCgXFZXXfTic"
      },
      "source": [
        "The next step to format the data for charting is to create an `fc_to_dict` function to convert the `ee.FeatureCollection` to `ee.Dictionary`. Then we convert the `ee.Dictionary` to a pandas dataframe, which is a common table format in python.\n",
        "\n",
        "Recall that Google Earth Engine works by sending code between your computer in the python API and Google's servers for computation. In order to plot charts without Google's built in Chart.UI functioning, we need to transfer the data from Google's server (often referred to in documentation as 'server side') to our own computers (referred to as 'client side'), which we do with the `.getInfo()` call. \n",
        "\n",
        "This workflow is very useful for integrating Google Earth Engine data with other python libraries and data processing functions, not just for charting. \n",
        "\n",
        "But now back to charting..."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tm2dR8G82Tqx"
      },
      "source": [
        "# Define a function to transfer feature properties to a dictionary.\n",
        "# We use this to convert our earth engine object (reduced image collection) to a \n",
        "# collection of properties and their values \n",
        "\n",
        "def fc_to_dict(fc):\n",
        "  prop_names = fc.first().propertyNames()\n",
        "  prop_lists = fc.reduceColumns(\n",
        "      reducer=ee.Reducer.toList().repeat(prop_names.size()),\n",
        "      selectors=prop_names).get('list')\n",
        "\n",
        "  return ee.Dictionary.fromLists(prop_names, prop_lists)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JY7wL2q7M6ir"
      },
      "source": [
        "Now we need to get the data, in the form of a dictionary, on to our own computer:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ev14reOzfemW"
      },
      "source": [
        "# Convert feature collection to dictionary and use .getInfo() to transfer to our own computers\n",
        "sst_dict = fc_to_dict(sst_stat_fc).getInfo()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bbzopM-kLLq"
      },
      "source": [
        "\n",
        "Now let's see what the dictionary looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y_ELWjBGlre1"
      },
      "source": [
        "# print normally\n",
        "print(sst_dict,\"\\n\") # \\n tells it to print a new line\n",
        "\n",
        "# print some of the dictionary with formatting\n",
        "for prop in sst_dict.keys():\n",
        "    print(prop + ':', sst_dict[prop][0:3] + ['...'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I6LwMbWDTw2b"
      },
      "source": [
        "In the dictionary format, lists of data are stored in properties in the format `{property1: [list of values1],property2: [list of values2]...}`. This can easily be converted to a dataframe by creating columns from the properties. To do that we will use the .DataFrame() function from the pandas library (which we imported as pd).\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tXbXDo9ZTufi"
      },
      "source": [
        "# Convert the dictionary to a dataframe to make the information easier to interpret\n",
        "sst_df = pd.DataFrame(sst_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "slq2Bfc-1JK-"
      },
      "source": [
        "Now let's see what the dataframe looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4QDEaGK1K7D"
      },
      "source": [
        "sst_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2w_OD6Fr1SkX"
      },
      "source": [
        "The data is easier to read and easier to manipulate when it is in the dataframe (table) format. \n",
        "\n",
        "The next step is to clean up the data before plotting. The `millis` property contains date and time information in a strange format so we will convert it to a format that is more intuitive and then create year, month, day, and day of the year (DOY) variables from it."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l1Min0cYzz8"
      },
      "source": [
        "# Function to add date variables to DataFrame.\n",
        "# This function just uses pandas functions on the millis column to create date time columns\n",
        "\n",
        "def add_date_info(df):\n",
        "  df['Timestamp'] = pd.to_datetime(df['millis'], unit='ms')\n",
        "  df['Year'] = pd.DatetimeIndex(df['Timestamp']).year\n",
        "  df['Month'] = pd.DatetimeIndex(df['Timestamp']).month\n",
        "  df['Day'] = pd.DatetimeIndex(df['Timestamp']).day\n",
        "  df['DOY'] = pd.DatetimeIndex(df['Timestamp']).dayofyear\n",
        "  return df  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fIDeMoqk2DT7"
      },
      "source": [
        "# apply the date info function to the dataframe\n",
        "sst_df = add_date_info(sst_df)\n",
        "\n",
        "# Rename the sst column SST and remove the unnecessary millis and system:index columns\n",
        "sst_df = sst_df.rename(columns={\n",
        "    'sst': 'SST'\n",
        "}).drop(columns=['millis', 'system:index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bazyYvkd3OPQ"
      },
      "source": [
        "Now let's see what our cleaned up dataframe looks like."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LR4n0SPp3Rq7"
      },
      "source": [
        "sst_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIoC5HTa4po1"
      },
      "source": [
        "#### Plotting the Dataframe\n",
        "\n",
        "The hard part is over. We now have our reduced (i.e. summarized) earth engine data in a table format. If you wanted to, you could export the table to a .csv and create a simple graph in excel. However, once you get used to it, charting in python is excellent and has tons of libraries and functions for creating beautiful custom graphs. Because we are working in a notebook, we can even make them interactive!\n",
        "\n",
        "We did not filter our image collection by date so our dataframe `sst_df` contains all of the data included in the MODIS Ocean Color Dataset, i.e. the median SST values for our Area Of Interest (AOI) since July 4th 2002. This data product is not daily, but it still contains a lot of data for us to visualize.\n",
        "\n",
        "Let's start by creating a scatterplot in matplotlib, which you may have used before. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSbBsskYrg4K"
      },
      "source": [
        "#### Matplotlib"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Li9ncRe0nJh6"
      },
      "source": [
        "# import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Set up the subplots. This is your base.\n",
        "fig, ax = plt.subplots(figsize=(14, 6))\n",
        "\n",
        "# Add scatter plot with blue points that are 20% opaque. Use DOY on the x, and SST on the y axis\n",
        "ax.scatter(sst_df['DOY'], sst_df['SST'],\n",
        "           c='black', alpha=0.2)\n",
        "\n",
        "# Add some parameters.\n",
        "ax.set_title('Lake Erie Surface Temperature Cycle', fontsize=16) # set the title\n",
        "ax.set_xlabel('Date', fontsize=14) # set the x-axis label\n",
        "ax.set_ylabel('Temperature [C]', fontsize=14) # set the y-axis label\n",
        "ax.set_ylim(-4, 30) # set the y-axis range\n",
        "ax.grid(lw=0.2) #set the opacity of the background grid to 20%\n",
        "\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MlQatnO8mpFs"
      },
      "source": [
        "Our graph shows us about what we would expect for a lake in the northern hemisphere! There seem to be a couple of outliers, but for the most part, the lake surface temperature follows the same pattern for all of our data points.\n",
        "\n",
        "Matplotlib is a standard that is very customizable (and has tons of support pages across the internet). However, there are other libraries that make it easier to create beautiful visualizations.\n",
        "\n",
        "For this exercise we will use Altair, but if you're interested, try checking out seaborn as well!\n",
        "\n",
        "#### Altair\n",
        "\n",
        "The matplotlib chart we created is nice, but it is only presenting some of the information we have because it is not separating out the different years. Let's try another chart with Altair where we plot different years in different colours. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mpHso2EsJkJ"
      },
      "source": [
        "# Set the chart base up\n",
        "base = alt.Chart(sst_df).encode(\n",
        "    # set x-axis with DOY (see explanation of Q in comments below)\n",
        "    # the scale specifies the range of our x-axis\n",
        "    x=alt.X('DOY:Q', scale=alt.Scale(domain=[0, 370])),\n",
        "    # set y-axis as SST and set range from -5 to 30\n",
        "    y=alt.Y('SST:Q', scale=alt.Scale(domain=[-5, 30])),\n",
        "    # Change the point colours by Year value using the viridis colour scheme\n",
        "    color=alt.Color('Year:O', scale=alt.Scale(scheme='viridis')))\n",
        "\n",
        "# add the points to the map as circles\n",
        "points = base.mark_circle()\n",
        "\n",
        "# set overall properties\n",
        "(points).properties(width=600, height=350)\n",
        "\n",
        "## Note: Altair uses Q and O to specify the kind of data\n",
        "# Q = quantitative, or continuous data (like SST)\n",
        "# O = ordinal, or categorical data (like Year)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GEtXyzBvbAow"
      },
      "source": [
        "This graph now helps us see which years the outliers are in. It seems like the outliers come from many different years -- there is no obvious trend of one year having higher or lower than normal SST.\n",
        "\n",
        "As mentioned, Altair also allows for interactive charts. Now we can adapt the above code to make it interactive. We will also add lines that connect our points for each year to our chart."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6f-xb0mHFf6U"
      },
      "source": [
        "# Set the highlight parameters\n",
        "# When we hover our mouse over a point, we want all the points that share that year\n",
        "# to be highlighted\n",
        "highlight = alt.selection(\n",
        "    type='single', on='mouseover', fields=['Year'], nearest=True)\n",
        "\n",
        "# Set the base, this is the same as above.\n",
        "base = alt.Chart(sst_df).encode(\n",
        "    x=alt.X('DOY:Q', scale=alt.Scale(domain=[0, 370])),\n",
        "    y=alt.Y('SST:Q', scale=alt.Scale(domain=[-5, 30])),\n",
        "    color=alt.Color('Year:O', scale=alt.Scale(scheme='turbo')))\n",
        "\n",
        "# Add points - change the size based on the highlight condition we set above\n",
        "points = base.mark_circle().encode(\n",
        "    size=alt.condition(~highlight, alt.value(10), alt.value(15)),\n",
        "    tooltip=[\n",
        "        alt.Tooltip('Year:O', title='Year'),\n",
        "        alt.Tooltip('DOY:Q', title='DOY'),\n",
        "        alt.Tooltip('SST:Q', title='SST')\n",
        "    ]).add_selection(highlight)\n",
        "\n",
        "# Add lines - change the size based on the highlight condition\n",
        "lines = base.mark_line().encode(\n",
        "    size=alt.condition(~highlight, alt.value(1), alt.value(4)))\n",
        "\n",
        "# Set the chart properties and add .interactive()\n",
        "(points + lines).properties(width=600, height=350).interactive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gMGUR4IBJgRa"
      },
      "source": [
        "The above chart is interactive - when you hover over a value, it will give you information about the point. You can also zoom in on the graph and drag it up, down, right, and left.\n",
        "\n",
        "Interactive maps and charts are a great way to make use of notebook functionality. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k40yKnLH4nlh"
      },
      "source": [
        "#### Plot Chl-a Trend for 2015\n",
        "\n",
        "For our last example, we will modify our code from above to look at the trend in chlorophyll concentration for 2015. There was a big algal bloom in 2015 in Lake Erie, which we should be able to see if we plot out the values. The code below follows the same structure that we used above for SST, but without all the comments so you see it in a more condensed format.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qwSU20MCUsRn"
      },
      "source": [
        "##### SET UP IMAGE COLLECTION AND AOI #####\n",
        "\n",
        "# Create a collection from the chlor_a (Chlorophyll-a concentration) band\n",
        "chla = modisOceanColor.select(['chlor_a'])\n",
        "\n",
        "# Define an area of interest (aoi)\n",
        "aoi = ee.Geometry.Polygon([[-83.594,41.326],\n",
        "                           [-78.782,41.326],\n",
        "                           [-78.782,42.972],\n",
        "                           [-83.594,42.972],\n",
        "                           [-83.594,41.326]])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z8gsGrh1VJ2N"
      },
      "source": [
        "##### REDUCE IMAGE COLL #####\n",
        "\n",
        "# Create reducer function for mapping across image collection\n",
        "reduce_chla = create_reduce_region_function(\n",
        "    geometry=aoi, reducer=ee.Reducer.median())\n",
        "\n",
        "# Map reducing function across image collection and convert it to feature collection\n",
        "chla_stat_fc = ee.FeatureCollection(chla.map(reduce_chla))\n",
        "\n",
        "# Clean up by removing null values\n",
        "chla_stat_fc = chla_stat_fc.filter(\n",
        "    ee.Filter.notNull(chla.first().bandNames()))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jlZviYDCVYFS"
      },
      "source": [
        "##### CONVERT COLLECTION TO TABLE #####\n",
        "\n",
        "# Convert ee feature collection to 'client-side' dictionary\n",
        "chla_dict = fc_to_dict(chla_stat_fc).getInfo()\n",
        "\n",
        "# Convert dictionary to dataframe and add date info\n",
        "chla_df = pd.DataFrame(chla_dict)\n",
        "chla_df = add_date_info(chla_df)\n",
        "\n",
        "# Clean up data columns and remove unnecessary columns\n",
        "chla_df = chla_df.drop(columns=['millis', 'system:index'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2_edoLetGERQ"
      },
      "source": [
        "chla_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mFqvt8exWq7J"
      },
      "source": [
        "So far, most of what we have done is the exact same as what we did for sea surface temperature above. We have just changed our band to be `chlor_a` instead of `sst` and we changed our variable names to reflect that change. \n",
        "\n",
        "Our dataframe contains all of the data since 2002 but we just want data for 2015. We ***could*** have filtered our image collection at the beginning, the same way we did in previous labs, which would have been less data intensive because it would have meant that we didn't need to convert values from all of the other years to a dictionary and a dataframe. However, we can also filter our dataframe, which gives us a bit more flexibility in case we want to plot other years. It also gives us the opportunity to use some pandas functions to filter the table/dataframe."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlJZ6a-4RQuI"
      },
      "source": [
        "# Filter dataframe using loc\n",
        "# This line creates a new dataframe that only include rows from the\n",
        "# original df that have values of 2015 in the Year column\n",
        "\n",
        "chla2015_df = chla_df.loc[chla_df['Year'] == 2015]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flnrNcSRRPsH"
      },
      "source": [
        "highlight = alt.selection(\n",
        "    type='single', on='mouseover', fields=['chlor_a'], nearest=True)\n",
        "\n",
        "base = alt.Chart(chla2015_df).encode(\n",
        "    x=alt.X('DOY:Q', scale=alt.Scale(domain=[0, 370]),title = \"Day of the Year\"),\n",
        "    y=alt.Y('chlor_a:Q', scale=alt.Scale(domain=[0,15]),title='Chl-a Concentration'),\n",
        "    # use the goldgreen color scheme and set the variable as Q (continuous)\n",
        "    color=alt.Color('chlor_a:Q', scale=alt.Scale(scheme='goldgreen'))) \n",
        "\n",
        "points = base.mark_circle().encode(\n",
        "    size=alt.condition(~highlight, alt.value(100), alt.value(120)),\n",
        "    tooltip=[\n",
        "        alt.Tooltip('Year:O', title='Year'),\n",
        "        alt.Tooltip('DOY:Q', title='DOY'),\n",
        "        alt.Tooltip('chlor_a:Q', title='Chl-a')\n",
        "    ]).add_selection(highlight)\n",
        "\n",
        "(points).properties(width=600, height=350).interactive()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fa4g08gZfIId"
      },
      "source": [
        "In the chart above, we didn't need to colour the points based on chl-a concentration because it doesn't add any additional information (we already see the Chl-a pattern based on their position on the chart). However, it can be a useful visualization tool to put the focus on the change of values. You can use a single colour by changing the above code for base to this:\n",
        "\n",
        "```\n",
        "base = alt.Chart(sst2015_df).encode(\n",
        "    x=alt.X('DOY:Q', scale=alt.Scale(domain=[0, 370]),title = \"Day of the Year\"),\n",
        "    y=alt.Y('chlor_a:Q', scale=alt.Scale(domain=[0,15]),title='Chl-a Concentration'),\n",
        "    color=alt.value('green')) \n",
        "```\n",
        "\n",
        "The chart above shows that there are some pretty high Chl-a values in the late summer. Let's check out what the surface reflectance and Chl-a values look like on a map!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N2AC4OXAfV6B"
      },
      "source": [
        "SR_Aug2015 = ee.ImageCollection('MODIS/006/MOD09GA')\\\n",
        "        .filterDate('2015-08-01', '2015-09-30')\\\n",
        "        .filterBounds(aoi)\\\n",
        "        .map(maskEmptyPixels)\\\n",
        "        .map(maskClouds)\\\n",
        "        .median()\n",
        "\n",
        "SR_May2015 = ee.ImageCollection('MODIS/006/MOD09GA')\\\n",
        "        .filterDate('2015-04-01', '2015-05-31')\\\n",
        "        .filterBounds(aoi)\\\n",
        "        .map(maskEmptyPixels)\\\n",
        "        .map(maskClouds)\\\n",
        "        .median()\n",
        "\n",
        "\n",
        "Chla_Aug2015 = ee.ImageCollection('NASA/OCEANDATA/MODIS-Aqua/L3SMI').select(['chlor_a'])\\\n",
        "        .filterDate('2015-08-01', '2015-09-30')\\\n",
        "        .filterBounds(aoi)\\\n",
        "        .median()\n",
        "\n",
        "Chla_May2015 = ee.ImageCollection('NASA/OCEANDATA/MODIS-Aqua/L3SMI').select(['chlor_a'])\\\n",
        "        .filterDate('2015-04-01', '2015-05-31')\\\n",
        "        .filterBounds(aoi)\\\n",
        "        .median()\n",
        "\n",
        "SRvis = {'bands': ['sur_refl_b01', 'sur_refl_b04', 'sur_refl_b03'],\n",
        "     'gain': 0.07,\n",
        "     'gamma': 1.7\n",
        "    }\n",
        "\n",
        "Chlavis = {'min':0,'max':16,'palette': 'blue,teal,green'};\n",
        "\n",
        "Map = geemap.Map()\n",
        "Map.addLayer(SR_May2015,SRvis,'May 2015 Median SR')\n",
        "Map.addLayer(SR_Aug2015,SRvis,'Aug 2015 Median SR')\n",
        "Map.addLayer(Chla_May2015,Chlavis,'May 2015 Median Chla')\n",
        "Map.addLayer(Chla_Aug2015,Chlavis,'Aug 2015 Median Chla')\n",
        "Map.addLayerControl()\n",
        "Map.centerObject(aoi,8)\n",
        "Map"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0_5qQpMiOWx"
      },
      "source": [
        "We can definitely see a difference between the surface reflectances for April/May and August/September but the Chl-a values are very different! \n",
        "\n",
        "This is because Chl-a is calculated using more than just the RGB bands and thus shows more variation that we can discern just from true colour imagery. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KPRy-_lMk6O"
      },
      "source": [
        "## Questions to Submit\n",
        "\n",
        "[Total marks = 10]\n",
        "\n",
        "Answer the following questions in the space provided. Feel free to add additional code and text cells as needed. Make sure to show all of your code.\n",
        "\n",
        "**In all cases**, if you use code chunks from another source (not a bad thing), make sure to reference where you found them.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ChwDTz1iV_w4"
      },
      "source": [
        "### Q1\n",
        "\n",
        "Display the median 2018 SST value for the whole globe on a map. Use `'palette': 'navy,blue,turquoise'` in your visualization parameters. Make sure your minimum and maximum values make sense."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "99JY5vjBSNJL"
      },
      "source": [
        "## Show your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aapfa7sUSNgZ"
      },
      "source": [
        "### Q2\n",
        "\n",
        "Create a scatter plot showing the median SST over 2018 for an area of your choice anywhere in the world (over water, of course). You can either choose a point, or a rectangle to define your area. Hint: you can get latitudes and longitudes by clicking on a map in this notebook or in google maps."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1GfsFwlWeWD"
      },
      "source": [
        "## Show your code here"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gfzX-hPrScJP"
      },
      "source": [
        "### Q3\n",
        "\n",
        "Now that you have used Google Earth Engine, what do you think about it? Did you find it useful and/or interesting? What are its strengths and weaknesses? Are there any things you have found particularly difficult? Are there things you have noticed that are particularly cool? Describe your experience in full sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kh0ePD3Mnn-f"
      },
      "source": [
        "// Write your answer here"
      ]
    }
  ]
}
